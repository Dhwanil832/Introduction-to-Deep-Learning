{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import os"
      ],
      "metadata": {
        "id": "IPIt6W4rFMwy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Base URL\n",
        "base_url = 'https://www.purdue.edu/newsroom/articles/'\n",
        "start_url = f'{base_url}?order=DESC&orderby=date&paged=1&filter_year=2022&custom_post_type=post,purduetoday'\n",
        "\n",
        "# Create a folder for images\n",
        "output_folder = \"purdue_images_2022\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Function to download images\n",
        "def download_image(img_url, folder):\n",
        "    try:\n",
        "        response = requests.get(img_url, stream=True)\n",
        "        if response.status_code == 200:\n",
        "            filename = os.path.join(folder, img_url.split(\"/\")[-1])\n",
        "            with open(filename, 'wb') as file:\n",
        "                for chunk in response.iter_content(1024):\n",
        "                    file.write(chunk)\n",
        "            print(f\"Downloaded: {filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to download {img_url}: {e}\")\n",
        "\n",
        "# Function to get images from a page\n",
        "def get_images_from_page(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    # Select image tags based on page context\n",
        "    images = soup.find_all('img')\n",
        "    for img in images:\n",
        "        img_url = img.get('src')\n",
        "        if img_url and img_url.startswith('http'):\n",
        "            download_image(img_url, output_folder)\n",
        "\n",
        "\n",
        "for page_number in range(1, 37):\n",
        "    page_url = f\"{base_url}?order=DESC&orderby=date&paged={page_number}&filter_year=2022&custom_post_type=post,purduetoday\"\n",
        "    print(f\"Scraping page: {page_url}\")\n",
        "    get_images_from_page(page_url)\n",
        "\n",
        "print(\"Scraping complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWMYoWGJGv5X",
        "outputId": "e8df7918-ea03-490a-c446-09f25576b946"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page: https://www.purdue.edu/newsroom/articles/?order=DESC&orderby=date&paged=1&filter_year=2022&custom_post_type=post,purduetoday\n",
            "Scraping page: https://www.purdue.edu/newsroom/articles/?order=DESC&orderby=date&paged=2&filter_year=2022&custom_post_type=post,purduetoday\n",
            "Downloaded: purdue_images_2022/PU-H-light.svg\n",
            "Downloaded: purdue_images_2022/search-menu-icon.png\n",
            "Downloaded: purdue_images_2022/close_icon_black.svg\n",
            "Downloaded: purdue_images_2022/close_icon.svg\n",
            "Downloaded: purdue_images_2022/pt-AO-social.jpg\n",
            "Downloaded: purdue_images_2022/pt-grant-garage-800x533-1.jpg\n",
            "Downloaded: purdue_images_2022/wintergatewaytothefuture.jpg\n",
            "Downloaded: purdue_images_2022/StaffExcellencePMU.jpg\n",
            "Downloaded: purdue_images_2022/PurdueSunset-min.png\n",
            "Downloaded: purdue_images_2022/2412CFIfeature.jpg\n",
            "Downloaded: purdue_images_2022/minaisesisters-diplomas.jpg\n",
            "Downloaded: purdue_images_2022/BrandsThatMatter2024.jpg\n",
            "Downloaded: purdue_images_2022/faculty-years-senate-luncheon.jpg\n",
            "Downloaded: purdue_images_2022/duerstock-dysreflexiadevice.jpg\n",
            "Downloaded: purdue_images_2022/PG24-BerryShelbi.jpg\n",
            "Downloaded: purdue_images_2022/roy-chipsaiinstitute.jpg\n",
            "Downloaded: purdue_images_2022/PU-V.svg\n",
            "Scraping page: https://www.purdue.edu/newsroom/articles/?order=DESC&orderby=date&paged=3&filter_year=2022&custom_post_type=post,purduetoday\n",
            "Downloaded: purdue_images_2022/PU-H-light.svg\n",
            "Downloaded: purdue_images_2022/search-menu-icon.png\n",
            "Downloaded: purdue_images_2022/close_icon_black.svg\n",
            "Downloaded: purdue_images_2022/close_icon.svg\n",
            "Downloaded: purdue_images_2022/falltalkinghead.jpg\n",
            "Downloaded: purdue_images_2022/PurdueMemorialUnionSunset-min.png\n",
            "Downloaded: purdue_images_2022/hovde-winterLO-2.jpg\n",
            "Downloaded: purdue_images_2022/fountain-winterLO.jpg\n",
            "Downloaded: purdue_images_2022/PT-2024_KAL_5135.jpg\n",
            "Downloaded: purdue_images_2022/bell-tower-fall.jpg\n",
            "Downloaded: purdue_images_2022/hovde-winterLO-3.jpg\n",
            "Downloaded: purdue_images_2022/unfinished-blockp.jpg\n",
            "Downloaded: purdue_images_2022/wintergatewaytothefuture.jpg\n",
            "Downloaded: purdue_images_2022/PG-DistinctionAwards24-1.jpg\n",
            "Downloaded: purdue_images_2022/Greg-Deason.png\n",
            "Downloaded: purdue_images_2022/PU-V.svg\n",
            "Scraping page: https://www.purdue.edu/newsroom/articles/?order=DESC&orderby=date&paged=4&filter_year=2022&custom_post_type=post,purduetoday\n",
            "Downloaded: purdue_images_2022/PU-H-light.svg\n",
            "Downloaded: purdue_images_2022/search-menu-icon.png\n",
            "Downloaded: purdue_images_2022/close_icon_black.svg\n",
            "Downloaded: purdue_images_2022/close_icon.svg\n",
            "Downloaded: purdue_images_2022/belltower-fall.jpg\n",
            "Downloaded: purdue_images_2022/cropped-cropped-pt-westwood-exterior-876x493-1.jpg\n",
            "Downloaded: purdue_images_2022/RJM-8744_1200px.jpg\n",
            "Downloaded: purdue_images_2022/2023fall-leaves.jpg\n",
            "Downloaded: purdue_images_2022/COE-12-engineeringArch-876X493.jpg\n",
            "Downloaded: purdue_images_2022/cropped-Purdue-Arch-2023_KAL_4869.jpg\n",
            "Downloaded: purdue_images_2022/pt-pupd-newofficers-876x493-1.jpg\n",
            "Downloaded: purdue_images_2022/pt-gpu-876x493-2.jpg\n",
            "Downloaded: purdue_images_2022/hovde.jpg\n",
            "Downloaded: purdue_images_2022/pt-campus-connect-800x533-1.jpg\n",
            "Downloaded: purdue_images_2022/BrionyHorgan-Perseverance-scaled.jpg\n",
            "Downloaded: purdue_images_2022/campus-aerialBOT241004.jpg\n",
            "Downloaded: purdue_images_2022/PU-V.svg\n",
            "Scraping complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "# Specify device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Check if cuda is available, otherwise use cpu\n",
        "\n",
        "# Load the image using Pillow\n",
        "raw_image = Image.open('/content/articles/purdue_images_2022/GatewayArchLO-1.jpg')\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "# Load the model and move it to the selected device\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
        "\n",
        "text = \"a photography of\"\n",
        "\n",
        "# conditional image captioning\n",
        "inputs = processor(raw_image, text, return_tensors=\"pt\").to(device)\n",
        "out = model.generate(**inputs)\n",
        "c_decoded_out = processor.decode(out[0], skip_special_tokens=True)\n",
        "# unconditional image captioning\n",
        "inputs = processor(raw_image, return_tensors=\"pt\").to(device)\n",
        "out = model.generate(**inputs)\n",
        "uc_decoded_out = processor.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"Conditional Image Caption:\", c_decoded_out)\n",
        "print(\"Unconditional Image Caption:\", uc_decoded_out)\n",
        "\n",
        "del processor, model, raw_image, out, inputs"
      ],
      "metadata": {
        "id": "p0qtpoP7G5u8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc305ea3-1d4d-4261-9aa3-92c04eceb32c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conditional Image Caption: a photography of a college campus\n",
            "Unconditional Image Caption: a large arch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "# Specify device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Check if cuda is available, otherwise use cpu\n",
        "\n",
        "# Load the image using Pillow\n",
        "raw_image = Image.open('/content/articles/purdue_images_2022/fountain-winterLO.jpg')\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "# Load the model and move it to the selected device\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
        "\n",
        "text = \"a photography of\"\n",
        "\n",
        "# conditional image captioning\n",
        "inputs = processor(raw_image, text, return_tensors=\"pt\").to(device)\n",
        "out = model.generate(**inputs)\n",
        "c_decoded_out = processor.decode(out[0], skip_special_tokens=True)\n",
        "# unconditional image captioning\n",
        "inputs = processor(raw_image, return_tensors=\"pt\").to(device)\n",
        "out = model.generate(**inputs)\n",
        "uc_decoded_out = processor.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"Conditional Image Caption:\", c_decoded_out)\n",
        "print(\"Unconditional Image Caption:\", uc_decoded_out)\n",
        "\n",
        "del processor, model, raw_image, out, inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a61w-A8-Rs5C",
        "outputId": "38d2b57f-07eb-4037-96bc-92106ffc503a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conditional Image Caption: a photography of a snow covered walkway\n",
            "Unconditional Image Caption: a large stone structure\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "# Specify device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Check if cuda is available, otherwise use cpu\n",
        "\n",
        "# Load the image using Pillow\n",
        "raw_image = Image.open('/content/articles/purdue_images_2022/campus-fallLO.jpg')\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "# Load the model and move it to the selected device\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
        "\n",
        "text = \"a photography of\"\n",
        "\n",
        "# conditional image captioning\n",
        "inputs = processor(raw_image, text, return_tensors=\"pt\").to(device)\n",
        "out = model.generate(**inputs)\n",
        "c_decoded_out = processor.decode(out[0], skip_special_tokens=True)\n",
        "# unconditional image captioning\n",
        "inputs = processor(raw_image, return_tensors=\"pt\").to(device)\n",
        "out = model.generate(**inputs)\n",
        "uc_decoded_out = processor.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"Conditional Image Caption:\", c_decoded_out)\n",
        "print(\"Unconditional Image Caption:\", uc_decoded_out)\n",
        "\n",
        "del processor, model, raw_image, out, inputs"
      ],
      "metadata": {
        "id": "rQTul39RS5Gs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f03c867-261b-4d93-f4ce-9e21c356e155"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conditional Image Caption: a photography of a fountain\n",
            "Unconditional Image Caption: a fountain in a park\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "# Specify device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Check if cuda is available, otherwise use cpu\n",
        "\n",
        "# Load the image using Pillow\n",
        "raw_image = Image.open('/content/articles/purdue_images_2022/earhartstatue-fall.jpg')\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "# Load the model and move it to the selected device\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
        "\n",
        "text = \"a photography of\"\n",
        "\n",
        "# conditional image captioning\n",
        "inputs = processor(raw_image, text, return_tensors=\"pt\").to(device)\n",
        "out = model.generate(**inputs)\n",
        "c_decoded_out = processor.decode(out[0], skip_special_tokens=True)\n",
        "# unconditional image captioning\n",
        "inputs = processor(raw_image, return_tensors=\"pt\").to(device)\n",
        "out = model.generate(**inputs)\n",
        "uc_decoded_out = processor.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"Conditional Image Caption:\", c_decoded_out)\n",
        "print(\"Unconditional Image Caption:\", uc_decoded_out)\n",
        "\n",
        "del processor, model, raw_image, out, inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLjUVi8VfyqG",
        "outputId": "00df315f-bca1-44dc-f418-a5146b0edc50"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conditional Image Caption: a photography of a statue of a man holding a baseball bat\n",
            "Unconditional Image Caption: a statue of a man holding a baseball bat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "# Specify device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Check if cuda is available, otherwise use cpu\n",
        "\n",
        "# Load the image using Pillow\n",
        "raw_image = Image.open('/content/articles/purdue_images_2022/belltower-fall.jpg')\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "# Load the model and move it to the selected device\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
        "\n",
        "text = \"a photography of\"\n",
        "\n",
        "# conditional image captioning\n",
        "inputs = processor(raw_image, text, return_tensors=\"pt\").to(device)\n",
        "out = model.generate(**inputs)\n",
        "c_decoded_out = processor.decode(out[0], skip_special_tokens=True)\n",
        "# unconditional image captioning\n",
        "inputs = processor(raw_image, return_tensors=\"pt\").to(device)\n",
        "out = model.generate(**inputs)\n",
        "uc_decoded_out = processor.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"Conditional Image Caption:\", c_decoded_out)\n",
        "print(\"Unconditional Image Caption:\", uc_decoded_out)\n",
        "\n",
        "del processor, model, raw_image, out, inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8971II23gG07",
        "outputId": "ecf72313-8e53-4939-f959-1ed1e7976511"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conditional Image Caption: a photography of a clock tower with a sky background\n",
            "Unconditional Image Caption: a clock tower\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DT7SNlF6gZhV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}